---
title: "Redistricting in Pennsylvania"
categories: R, GIS
date: '2019-04-21'
image:
  preview_only: yes
share: false
summary: Analyzing the partisan impact of court-ordered redistricting in Pennsylvania.
tags: ["r", "gis", "redistricting"]

authors: 
- admin
---

<link href="{{< relref "post/pa-redistricting/index.html" >}}index_files/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="{{< relref "post/pa-redistricting/index.html" >}}index_files/anchor-sections/anchor-sections.js"></script>


<div class="figure">
<img src="featured.png" alt="Elkanah Tisdale (1771-1835) (often falsely attributed to Gilbert Stuart) / Public domain" />
<p class="caption">Elkanah Tisdale (1771-1835) (often falsely attributed to Gilbert Stuart) / Public domain</p>
</div>
<p>Pennsylvania's Congressional district map has been a source of contention between Republicans and Democrats for years. In 2004, members of the Democratic Party challenged the Republican-drawn district map on the grounds that it violated the principle of one-man, one-vote and thus denied Democratic voters representation in Congress. The case was brought to the Supreme Court as <a href="https://www.oyez.org/cases/2003/02-1580"><em>Vieth v. Jubelirer</em></a>, but the issue was found nonjusticiable and the map was allowed to stand. In his opinion, Justice Kennedy noted that while no judicial standard for assessing the partisanship of a given map yet existed, the Court should remain open to the possibility that one might emerge in the coming years.</p>
<p>In 2011, again in control of state government, Pennsylvania Republicans implemented a new gerrymander which further solidified their advantage in Congress. The map helped protect Republican candidates in 2012, 2014, and 2016, but was struck down in early 2018 by the state Supreme Court on the grounds that it was &quot;clearly, plainly, and palpably&quot; in violation of the state constitution. A new non-partisan map, drawn by the court with the help of Stanford Law professor Nathaniel Persily, was implemented in time for the May 15th, 2018 state primaries and will remain in effect until the decennial redistricting following the 2020 census. In this post I'll use recent electoral data from Pennsylvania to explore the partisan effects of redistricting on representation.</p>
<div id="labelling-precincts-with-the-correct-congressional-districts" class="section level2">
<h2>Labelling precincts with the correct Congressional districts</h2>
<p>I downloaded election data from <a href="https://github.com/nvkelso/election-geodata/tree/migurski/add-pa-2016/data/42-pennsylvania/statewide">Nathaniel Kelso and Michal Migurski's GitHub repo</a> and will focus on the 2016 election results from Pennsylvania.</p>
<p>Here are the maps that were involved in the latest suit:</p>
<ul>
<li><p>The 2011 Republican gerrymander, available from the <a href="https://www.census.gov/geo/maps-data/data/cbf/cbf_cds.html">U.S. Census Bureau</a>.</p></li>
<li><p>The remedial plan, available from the website of the plaintiffs, <a href="http://www.pacourts.us/news-and-statistics/cases-of-public-interest/league-of-women-voters-et-al-v-the-commonwealth-of-pennsylvania-et-al-159-mm-2017">The League of Women Voters</a>.</p></li>
</ul>
<p>To start things off, I'll just focus on the gerrymandered map. Let's begin by cleaning the data.</p>
<pre class="r"><code># Precinct-level election data from 2016
penn &lt;- 
  st_read(file_penn) %&gt;% 
  select(
    precinct = OBJECTID,
    pres_d = T16PRESD, # Clinton vote total
    pres_r = T16PRESR, # Trump vote total
    cong_d = T16CONGD, # Dem HOR vote total
    cong_r = T16CONGR # GOP HOR vote total
  )</code></pre>
<pre><code>## Reading layer `VTDs_Oct17&#39; from data source `/Users/Benjamin/personal-website/content/post/pa-redistricting/data/VTDs_Oct17/VTDs_Oct17.shp&#39; using driver `ESRI Shapefile&#39;
## Simple feature collection with 9152 features and 46 fields
## geometry type:  MULTIPOLYGON
## dimension:      XY
## bbox:           xmin: -80.5195 ymin: 39.7198 xmax: -74.6895 ymax: 42.26933
## CRS:            4326</code></pre>
<pre class="r"><code># 115th Congress district shapefiles
dist_115 &lt;- 
  st_read(file_dist) %&gt;% 
  filter(STATEFP == 42) %&gt;% 
  st_transform(crs = 4326) %&gt;% 
  select(cd = CD115FP)</code></pre>
<pre><code>## Reading layer `cb_2017_us_cd115_500k&#39; from data source `/Users/Benjamin/personal-website/content/post/pa-redistricting/data/cb_2017_us_cd115_500k/cb_2017_us_cd115_500k.shp&#39; using driver `ESRI Shapefile&#39;
## Simple feature collection with 441 features and 8 fields
## geometry type:  MULTIPOLYGON
## dimension:      XY
## bbox:           xmin: -179.1489 ymin: -14.5487 xmax: 179.7785 ymax: 71.36516
## CRS:            4269</code></pre>
<p>The <code>penn</code> object contains precinct-level election and census data which is organized by county, but not district. The <code>dist_115</code> file contains geographic information about the district. With just the <code>geometry</code> data for the precincts and the districts, I can use the <code>sf</code> package to generate a tibble containing a unique best guess for each precinct's assigned congressional district. I handle this by using <code>st_intersection()</code> to create new geometries that represent each precinct's intersection with one or more of the congressional district shapes, and then selecting the district that produces the greatest overlap, measured by <code>st_area()</code>.</p>
<pre class="r"><code>penn_115 &lt;-
  st_intersection(dist_115, penn) %&gt;%
  as_tibble() %&gt;%
  mutate(
    area =  st_area(geometry)
  ) %&gt;%
  group_by(precinct) %&gt;% 
  filter(area == max(area)) %&gt;% 
  ungroup() %&gt;% 
  select(precinct, cd, everything(), -area) %&gt;% 
  st_as_sf() </code></pre>
<p>Here's what the map looks like — each Congressional District now consists of several constituent precinct shapes.</p>
<pre class="r"><code># Results
penn_115 %&gt;% 
  ggplot() + 
  geom_sf(aes(fill = cd), size = .05, alpha = .5, show.legend = FALSE) +
  geom_sf(data = dist_115, color = &quot;black&quot;, size = .15, fill = NA) +
  theme_void() +
  coord_sf(datum = NA) </code></pre>
<p><img src="{{< relref "post/pa-redistricting/index.html" >}}index_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="comparing-election-results-under-different-district-maps" class="section level2">
<h2>Comparing election results under different district maps</h2>
<p>Now that I've developed a method to assign each precinct to its congressional district, I can use the voting data from 2016 to compile election results in each district.</p>
<pre class="r"><code>penn_115 %&gt;% 
  group_by(cd) %&gt;% 
  summarise(
    rep_margin = (sum(cong_r) - sum(cong_d)) /
      (sum(cong_r) + sum(cong_d))
  ) %&gt;% 
  ungroup() %&gt;% 
  ggplot() +
  geom_sf(aes(fill = rep_margin), size = 0) +
  geom_sf(data = dist_115, color = &quot;black&quot;, size = .1, fill = NA) +
  scale_fill_gradient2(
    low = &quot;#1A80C4&quot;,
    high = &quot;#CC3D41&quot;,
    labels = scales::percent,
    breaks = c(-1, -.5, 0, .5, 1),
    limits = c(-1, 1)
  ) +
  guides(
    fill = guide_colorbar(
      nbin = 10, 
      barheight = .25,
      barwidth = 9,
      raster = FALSE,
      ticks = FALSE,
      title.position = &quot;top&quot;
    )
  ) + 
  theme_void() +
  theme(legend.position = &quot;bottom&quot;) + 
  labs(fill = &quot;GOP Margin&quot;, title = &quot;2016 PA Congressional Election Results&quot;) +
  coord_sf(datum = NA)</code></pre>
<p><img src="{{< relref "post/pa-redistricting/index.html" >}}index_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>penn_115 %&gt;% 
  st_set_geometry(value = NULL) %&gt;% 
  group_by(cd) %&gt;% 
  summarise(
    rep_margin = (sum(cong_r) - sum(cong_d)) /
      (sum(cong_r) + sum(cong_d))
  ) %&gt;% 
  ungroup() %&gt;% 
  transmute(
    `District` = paste0(&quot;PA-&quot;, cd),
    `GOP Margin` = rep_margin %&gt;% scales::percent(accuracy = .1),
    `Winner` = if_else(rep_margin &gt; 0, &quot;GOP&quot;, &quot;Dems&quot;)
  ) %&gt;% 
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">District</th>
<th align="left">GOP Margin</th>
<th align="left">Winner</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PA-01</td>
<td align="left">-75.0%</td>
<td align="left">Dems</td>
</tr>
<tr class="even">
<td align="left">PA-02</td>
<td align="left">-77.9%</td>
<td align="left">Dems</td>
</tr>
<tr class="odd">
<td align="left">PA-03</td>
<td align="left">100.0%</td>
<td align="left">GOP</td>
</tr>
<tr class="even">
<td align="left">PA-04</td>
<td align="left">32.1%</td>
<td align="left">GOP</td>
</tr>
<tr class="odd">
<td align="left">PA-05</td>
<td align="left">34.4%</td>
<td align="left">GOP</td>
</tr>
<tr class="even">
<td align="left">PA-06</td>
<td align="left">14.4%</td>
<td align="left">GOP</td>
</tr>
<tr class="odd">
<td align="left">PA-07</td>
<td align="left">18.8%</td>
<td align="left">GOP</td>
</tr>
<tr class="even">
<td align="left">PA-08</td>
<td align="left">8.9%</td>
<td align="left">GOP</td>
</tr>
<tr class="odd">
<td align="left">PA-09</td>
<td align="left">26.7%</td>
<td align="left">GOP</td>
</tr>
<tr class="even">
<td align="left">PA-10</td>
<td align="left">40.3%</td>
<td align="left">GOP</td>
</tr>
<tr class="odd">
<td align="left">PA-11</td>
<td align="left">27.4%</td>
<td align="left">GOP</td>
</tr>
<tr class="even">
<td align="left">PA-12</td>
<td align="left">23.5%</td>
<td align="left">GOP</td>
</tr>
<tr class="odd">
<td align="left">PA-13</td>
<td align="left">-89.2%</td>
<td align="left">Dems</td>
</tr>
<tr class="even">
<td align="left">PA-14</td>
<td align="left">-48.7%</td>
<td align="left">Dems</td>
</tr>
<tr class="odd">
<td align="left">PA-15</td>
<td align="left">21.2%</td>
<td align="left">GOP</td>
</tr>
<tr class="even">
<td align="left">PA-16</td>
<td align="left">11.2%</td>
<td align="left">GOP</td>
</tr>
<tr class="odd">
<td align="left">PA-17</td>
<td align="left">-7.8%</td>
<td align="left">Dems</td>
</tr>
<tr class="even">
<td align="left">PA-18</td>
<td align="left">99.8%</td>
<td align="left">GOP</td>
</tr>
</tbody>
</table>
<p>Now let's do the same for the remedial map. I'm using the presidential vote totals because otherwise the voting dynamics imposed by the old map will skew the projected results. In PA-18, for instance, former GOP Rep. Tim Murphy ran unopposed in 2016 (before resigning in disgrace in 2017), so we'll substitute Clinton's vote share against Trump to stand in for a Democratic opponent in those precincts.</p>
<pre class="r"><code># Read in remedial shapefile
dist_remedial &lt;- 
  st_read(file_remedial) %&gt;% 
  st_transform(crs = 4326) %&gt;% 
  select(cd = DISTRICT)</code></pre>
<pre><code>## Reading layer `Remedial Plan Shapefile&#39; from data source `/Users/Benjamin/personal-website/content/post/pa-redistricting/data/Remedial Plan Shape Files - 006845/Remedial Plan Shapefile.shp&#39; using driver `ESRI Shapefile&#39;
## Simple feature collection with 18 features and 15 fields
## geometry type:  POLYGON
## dimension:      XY
## bbox:           xmin: -80.51985 ymin: 39.7198 xmax: -74.6895 ymax: 42.51607
## CRS:            4019</code></pre>
<pre class="r"><code># Create tibble of guesses
penn_remedial &lt;- 
  st_intersection(dist_remedial, penn) %&gt;%
  as_tibble() %&gt;% 
  mutate(
    area = st_area(geometry)
  ) %&gt;% 
  group_by(precinct) %&gt;% 
  filter(area == max(area)) %&gt;% 
  ungroup() %&gt;% 
  select(precinct, cd, everything(), -area) %&gt;% 
  st_as_sf()</code></pre>
<pre class="r"><code># Visualize the election results by district under the remedial plan
penn_remedial %&gt;% 
  group_by(cd) %&gt;% 
  summarise(
    trump_margin = (sum(pres_r) - sum(pres_d)) /
      (sum(pres_r) + sum(pres_d))
  ) %&gt;% 
  ungroup() %&gt;% 
  ggplot() +
  geom_sf(aes(fill = trump_margin), size = 0) +
  geom_sf(data = dist_remedial, color = &quot;black&quot;, size = .1, fill = NA) +
  scale_fill_gradient2(
    low = &quot;#1A80C4&quot;,
    high = &quot;#CC3D41&quot;,
    labels = scales::percent,
    breaks = c(-1, -.5, 0, .5, 1),
    limits = c(-1, 1)
  ) +
  guides(
    fill = guide_colorbar(
      nbin = 10, 
      barheight = .25,
      barwidth = 9,
      raster = FALSE,
      ticks = FALSE,
      title.position = &quot;top&quot;
    )
  ) + 
  theme_void() +
  theme(legend.position = &quot;bottom&quot;) +
  coord_sf(datum = NA) + 
  labs(
    fill = &quot;Trump Margin&quot;
  )</code></pre>
<p><img src="{{< relref "post/pa-redistricting/index.html" >}}index_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>penn_remedial %&gt;% 
  st_set_geometry(value = NULL) %&gt;% 
  group_by(cd) %&gt;% 
  summarise(
    trump_margin = (sum(pres_r) - sum(pres_d)) /
      (sum(pres_r) + sum(pres_d))
  ) %&gt;% 
  ungroup() %&gt;% 
  transmute(
    `District` = paste0(&quot;PA-&quot;, cd),
    `GOP Margin` = trump_margin %&gt;% scales::percent(accuracy = .1),
    `Winner` = if_else(trump_margin &gt; 0, &quot;GOP&quot;, &quot;Dems&quot;)
  ) %&gt;% 
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">District</th>
<th align="left">GOP Margin</th>
<th align="left">Winner</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PA-01</td>
<td align="left">-2.0%</td>
<td align="left">Dems</td>
</tr>
<tr class="even">
<td align="left">PA-02</td>
<td align="left">-49.1%</td>
<td align="left">Dems</td>
</tr>
<tr class="odd">
<td align="left">PA-03</td>
<td align="left">-85.7%</td>
<td align="left">Dems</td>
</tr>
<tr class="even">
<td align="left">PA-04</td>
<td align="left">-20.4%</td>
<td align="left">Dems</td>
</tr>
<tr class="odd">
<td align="left">PA-05</td>
<td align="left">-29.1%</td>
<td align="left">Dems</td>
</tr>
<tr class="even">
<td align="left">PA-06</td>
<td align="left">-9.8%</td>
<td align="left">Dems</td>
</tr>
<tr class="odd">
<td align="left">PA-07</td>
<td align="left">-1.2%</td>
<td align="left">Dems</td>
</tr>
<tr class="even">
<td align="left">PA-08</td>
<td align="left">9.8%</td>
<td align="left">GOP</td>
</tr>
<tr class="odd">
<td align="left">PA-09</td>
<td align="left">35.5%</td>
<td align="left">GOP</td>
</tr>
<tr class="even">
<td align="left">PA-10</td>
<td align="left">9.4%</td>
<td align="left">GOP</td>
</tr>
<tr class="odd">
<td align="left">PA-11</td>
<td align="left">27.2%</td>
<td align="left">GOP</td>
</tr>
<tr class="even">
<td align="left">PA-12</td>
<td align="left">37.9%</td>
<td align="left">GOP</td>
</tr>
<tr class="odd">
<td align="left">PA-13</td>
<td align="left">47.2%</td>
<td align="left">GOP</td>
</tr>
<tr class="even">
<td align="left">PA-14</td>
<td align="left">29.9%</td>
<td align="left">GOP</td>
</tr>
<tr class="odd">
<td align="left">PA-15</td>
<td align="left">44.9%</td>
<td align="left">GOP</td>
</tr>
<tr class="even">
<td align="left">PA-16</td>
<td align="left">20.9%</td>
<td align="left">GOP</td>
</tr>
<tr class="odd">
<td align="left">PA-17</td>
<td align="left">2.5%</td>
<td align="left">GOP</td>
</tr>
<tr class="even">
<td align="left">PA-18</td>
<td align="left">-27.9%</td>
<td align="left">Dems</td>
</tr>
</tbody>
</table>
<p>Using the presidential election data and the remedial plan, the Democrats would have carried eight seats, two more than they did under the old plan. However I should note that the gain I've modeled assumes that the races are being decided by the 2016 presidential electorate along party lines, when in reality... it's more complicated than that. I could probably pick a more representative set of results to model, but still, the effect is clear. And the districts look much better, too!</p>
</div>
<div id="measuring-a-maps-partisanship" class="section level2">
<h2>Measuring a map's partisanship</h2>
<p>Let's return to Justice Kennedy's question: How can a court objectively determine whether a map is the result of a partisan gerrymander?</p>
<p>In the years since <em>Vieth v. Jubelirer</em>, political scientists have come up with various statistical approaches to assess the observed partisanship of maps. With the methods above, I figure I can replicate some of their findings. I'll borrow from two of the most promising approaches developed by political scientists in the past few years.</p>
<ul>
<li><p><strong>The efficiency gap</strong>, devised by Nicholas Stephanopoulos and Eric McGhee, is a simple measure of how many votes each party &quot;wasted&quot; in a given election. A competitive, non-partisan map should theoretically have an efficiency gap close to zero. To calculate the estimated efficiency gap, I'm referncing this primer published by <a href="https://www.brennancenter.org/sites/default/files/legal-work/How_the_Efficiency_Gap_Standard_Works.pdf">The Brennan Center</a>.</p></li>
<li><p><strong>Simulated district maps</strong>, pioneered by Jowei Chen and David Cottrell, are used as non-partisan counterfactuals by which we can objectively measure partisan bias in existing maps. The simulations are constructed in order to be geographically compact, contiguous, and equally apportioned according to population and election data — factors which should inform the creation of non-partisan maps in real life. You can find hundreds of simulated maps on <a href="http://www-personal.umich.edu/~jowei/gerrymandering/">Chen's personal website</a>, however I'll just select one for illustrative purposes.</p></li>
</ul>
<pre class="r"><code>### Gerrymandered efficiency gap
efficiency_gap &lt;- function(d) {
  d %&gt;% 
    st_set_geometry(value = NULL) %&gt;% 
    group_by(cd) %&gt;% 
    summarise(
      d_votes = sum(cong_d),
      r_votes = sum(cong_r),
      d_wasted = if_else(
        d_votes &gt;= r_votes, 
        d_votes - (d_votes + r_votes) / 2, 
        d_votes
      ),
      r_wasted = if_else(
        d_votes &gt;= r_votes, 
        r_votes,
        r_votes - (r_votes + d_votes) / 2
      )
    ) %&gt;% 
    ungroup() %&gt;% 
    summarise_if(is.double, sum) %&gt;% 
    transmute(
      `Total Votes` = (d_votes + r_votes) %&gt;% scales::comma(),
      `Net Wasted Votes` = (d_wasted - r_wasted) %&gt;% scales::comma(),
      `Efficiency Gap` = ((d_wasted - r_wasted) / (d_votes + r_votes)) %&gt;% scales::percent(accuracy = .1)
    ) %&gt;% 
    knitr::kable()
}

efficiency_gap(penn_115)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Total Votes</th>
<th align="left">Net Wasted Votes</th>
<th align="left">Efficiency Gap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">5,698,604</td>
<td align="left">856,446</td>
<td align="left">15.0%</td>
</tr>
</tbody>
</table>
<p>The current map yields a 15% efficiency advantage for Republicans, meaning that compared to Democrats, they were able to convert their votes into 15% more seats, i.e. ~2.7 seats out of the 18 total in the Pennsylvania Congressional delegation. Now recall that just a few months into the first session of the 115th Congress, ACA repeal was passed in the House by just four votes.</p>
<pre class="r"><code>### Remedial efficiency gap
efficiency_gap(penn_remedial)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Total Votes</th>
<th align="left">Net Wasted Votes</th>
<th align="left">Efficiency Gap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">5,698,604</td>
<td align="left">464,204</td>
<td align="left">8.1%</td>
</tr>
</tbody>
</table>
<p>The new map still favors the Republicans, but only by 8%. This translates to roughly a 1.5 seat advantage, and thus provides a small boost to the Democrats. It also falls within Stephanopoulos and McGhee's suggested threshold of 2 seats for a non-partisan map.</p>
<p>Now let's compare these results to one of Chen and Cottrell's simulated maps.</p>
<pre class="r"><code>dist_sim &lt;- 
  st_read(file_simulated) %&gt;% 
  st_set_crs(4326) %&gt;% 
  select(cd = dist)</code></pre>
<pre><code>## Reading layer `plan_1&#39; from data source `/Users/Benjamin/personal-website/content/post/pa-redistricting/data/chen_cottrell_sim/plan_1.shp&#39; using driver `ESRI Shapefile&#39;
## Simple feature collection with 18 features and 17 fields
## geometry type:  POLYGON
## dimension:      XY
## bbox:           xmin: -80.51985 ymin: 39.7198 xmax: -74.6895 ymax: 42.51607
## CRS:            NA</code></pre>
<pre class="r"><code>penn_sim &lt;- 
  st_intersection(dist_sim, penn) %&gt;%
  as_tibble() %&gt;% 
  mutate(
    area = st_area(geometry)
  ) %&gt;% 
  group_by(precinct) %&gt;% 
  filter(area == max(area)) %&gt;% 
  ungroup() %&gt;% 
  select(precinct, cd, everything(), -area) %&gt;% 
  st_as_sf()</code></pre>
<pre class="r"><code>efficiency_gap(penn_sim)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Total Votes</th>
<th align="left">Net Wasted Votes</th>
<th align="left">Efficiency Gap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">5,698,604</td>
<td align="left">373,971</td>
<td align="left">6.6%</td>
</tr>
</tbody>
</table>
<p>The simulated map results in an efficiency gap of 6.6%, or a ~1.2 seat advantage, also in favor of the Republicans. As it turns out, surprisingly few of the simulated maps from Chen and Cottrell's study result in a Democratic advantage — it's difficult to draw maps that favor Democrats due to the tendency of Democratic voters to cluster in densely populated and geographically confined urban areas. Along with political scientist Jonathan Rodden, <a href="https://www.nytimes.com/2014/01/26/opinion/sunday/its-the-geography-stupid.html">Chen has used these simulations</a> to argue that the Democrats' biggest problem is not partisan gerrymandering by Republicans, but the natural human geography of their voting base.</p>
<p>This does nothing to excuse the unnatural advantages of partisan gerrymandering, of course, and as we've seen (and has been proven in court), the Pennsylvania Republican party's map represented a blatant — and effective — power grab. In Congress, every voting member's voice counts equally, no matter where they live. In other words, every vote <em>counts</em>. We should be able to say the same for Pennsylvania's voters.</p>
</div>
